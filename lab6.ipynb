{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0YTYghT86z5"
      },
      "source": [
        "## Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "mqaEyHO-lFw3",
        "outputId": "09bf522f-e35e-4b92-a64b-9e32ce483a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (from jupyter) (4.4.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter) (7.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.29.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter) (7.16.6)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.6.3)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.36.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (6.4.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (1.8.14)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (7.0.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (8.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (25.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (26.4.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (2.27.3)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (3.1.6)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (2.2.5)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/lib/python3/dist-packages (from jupyterlab->jupyter) (59.6.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (2.15.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter) (2.2.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.13.4)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (3.0.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: bleach[css]!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (6.2.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (5.10.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.10.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.24.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/lib/python3/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.4.1)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.4.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (20.11.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.5.1)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.11.1)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.9.0.20241206)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install jupyter ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk7Y6fEqr7_I",
        "outputId": "4d5a830e-3d27-4d89-8790-d0a6ab5c7314",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: NVIDIA A100-PCIE-40GB\n"
          ]
        }
      ],
      "source": [
        "import os, random, time, math, numpy as np\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.amp import GradScaler, autocast\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.models import ViT_B_16_Weights\n",
        "\n",
        "SEED        = 42\n",
        "IMSIZE      = 224\n",
        "BATCH_CNN   = 128\n",
        "BATCH_VIT   = 64\n",
        "ACC_STEPS   = 2\n",
        "NUM_WORKERS = 4\n",
        "DEVICE      = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "print('Device:', torch.cuda.get_device_name(0) if DEVICE=='cuda' else 'CPU-only')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw-J_HUF9ETd"
      },
      "source": [
        "## Аугментации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L5MS3y9lFw4"
      },
      "source": [
        "### Базовые (`tf_basic`)\n",
        "- **RandomResizedCrop** → разбивает кадр, даёт модели видеть разные фрагменты.  \n",
        "- **HorizontalFlip** → отражения для симметрии.  \n",
        "- **Normalize** → приведение к одной шкале (ImageNet).\n",
        "\n",
        "### Усиленные (`tf_strong`)\n",
        "- **RandomResizedCrop (широкий диапазон)** → экстремальные обрезы и масштабы.  \n",
        "- **HorizontalFlip** → те же отражения.  \n",
        "- **ColorJitter** → случайные изменения цвета и яркости.  \n",
        "- **RandomErasing** → «стереть» участки, чтобы модель не заучивала фон.\n",
        "\n",
        "### Для валидации/теста (`tf_test`)\n",
        "- **Resize + CenterCrop** → одинаковый размер без дёрганий.  \n",
        "- **Normalize** → та же схема, что и в обучении."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_CO6JatsA_E",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tf_basic = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMSIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "tf_strong = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMSIZE, scale=(0.5, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.2),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.25, value='random'),\n",
        "])\n",
        "\n",
        "tf_test = transforms.Compose([\n",
        "    transforms.Resize(IMSIZE+32),\n",
        "    transforms.CenterCrop(IMSIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_4i5qjE9RNS"
      },
      "source": [
        "## Загрузчик данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EP8z03blFw5"
      },
      "source": [
        "**Food101**  \n",
        "- Содержит **101 класс** блюд (фотографии из реальной жизни) → проверенная сложная задача мультиклассовой классификации.  \n",
        "- Большой объём (≈ 101 000 изображений) → статистическая устойчивость и разнообразие ракурсов, освещения, фонов.  \n",
        "- Стандартные splits (train/val/test) → воспроизводимость экспериментов и удобство валидации.  \n",
        "- Основан на открытых данных — не нужно ручное собирание и аннотирование."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AMz6lZHsC3q",
        "outputId": "06eb7830-c9b8-4cd9-dff6-a502912c9775",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Классов: 101 — 60600/7575/7575\n"
          ]
        }
      ],
      "source": [
        "root    = './data'\n",
        "full_ds = datasets.Food101(root, download=True, transform=tf_basic)\n",
        "n       = len(full_ds)\n",
        "n_tr, n_val = int(0.8*n), int(0.1*n)\n",
        "n_te    = n - n_tr - n_val\n",
        "train_ds, val_ds, test_ds = random_split(\n",
        "    full_ds, [n_tr, n_val, n_te],\n",
        "    generator=torch.Generator().manual_seed(SEED)\n",
        ")\n",
        "val_ds.dataset.transform  = tf_test\n",
        "test_ds.dataset.transform = tf_test\n",
        "\n",
        "gen = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "tr_dl_cnn = DataLoader(train_ds, BATCH_CNN, shuffle=True,\n",
        "                       generator=gen,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "tr_dl_vit = DataLoader(train_ds, BATCH_VIT, shuffle=True,\n",
        "                       generator=gen,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "val_dl  = DataLoader(val_ds, BATCH_CNN, shuffle=False,\n",
        "                     num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "test_dl = DataLoader(test_ds, BATCH_CNN, shuffle=False,\n",
        "                     num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "NUM_CLASSES = len(full_ds.classes)\n",
        "print(f'Классов: {NUM_CLASSES} — {len(train_ds)}/{len(val_ds)}/{len(test_ds)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYJqkPw49YFJ"
      },
      "source": [
        "## Полезные приколы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDjutx-5lFw5"
      },
      "source": [
        "### Выбранные метрики\n",
        "\n",
        "- **Accuracy** (`accuracy_score`)  \n",
        "  Доля правильно угаданных классов во всём датасете.  \n",
        "  Показывает общую «простоту» задачи и позволяет быстро оценить себя на доминантных классах.\n",
        "\n",
        "- **Macro F1-score** (`f1_score(average='macro')`)  \n",
        "  Гармоническое среднее **precision** и **recall**, усреднённое по классам без взвешивания.  \n",
        "  Отражает способность модели удерживать баланс между точностью и полнотой даже на редких классах, игнорируя их соотношение в датасете.\n",
        "\n",
        "Вместе эти две метрики дают представление и об общей точности (accuracy), и о том, как модель работает на каждой категории (macro F1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB8GPI3bsEey",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    return accuracy_score(y_true, y_pred), f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def epoch_step(model, loader, criterion, opt=None, scaler=None, accum=1):\n",
        "    train = opt is not None\n",
        "    model.train(train)\n",
        "    y_t, y_p, running = [], [], 0.0\n",
        "    if train: opt.zero_grad()\n",
        "\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n",
        "        with autocast(device_type='cuda'):\n",
        "            out  = model(x)\n",
        "            loss = criterion(out, y) / (accum if train else 1)\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            if (i+1)%accum==0 or (i+1)==len(loader):\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad()\n",
        "        running += loss.item()*x.size(0)*(accum if train else 1)\n",
        "        y_t.append(y.cpu()); y_p.append(out.detach().cpu().argmax(1))\n",
        "\n",
        "    y_t = torch.cat(y_t); y_p = torch.cat(y_p)\n",
        "    acc,f1 = metrics(y_t,y_p)\n",
        "    return running/len(loader.dataset), acc, f1\n",
        "\n",
        "def fit(model, loader, epochs, lr, accum=1):\n",
        "    model.to(DEVICE)\n",
        "    opt  = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    sch  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, epochs)\n",
        "    crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    sc   = GradScaler()\n",
        "    best = {'acc':0}\n",
        "\n",
        "    for e in range(1,epochs+1):\n",
        "        _,tr_acc,_        = epoch_step(model, loader, crit, opt, sc, accum)\n",
        "        _,val_acc,val_f1  = epoch_step(model, val_dl, crit)\n",
        "        sch.step()\n",
        "        if val_acc>best['acc']:\n",
        "            best={'acc':val_acc,'f1':val_f1,'state':model.state_dict()}\n",
        "        print(f'E{e:02d}/{epochs}  train_acc {tr_acc:.3f}  val_acc {val_acc:.3f}  val_F1 {val_f1:.3f}')\n",
        "\n",
        "    model.load_state_dict(best['state'])\n",
        "    return model,best\n",
        "\n",
        "def evaluate(model,name):\n",
        "    model.eval(); y_t,y_p=[],[]\n",
        "    with torch.no_grad(), autocast(device_type='cuda'):\n",
        "        for x,y in test_dl:\n",
        "            p = model(x.to(DEVICE)).argmax(1).cpu()\n",
        "            y_t.append(y); y_p.append(p)\n",
        "    acc,f1 = metrics(torch.cat(y_t),torch.cat(y_p))\n",
        "    print(f'{name}: acc {acc:.3f}  F1 {f1:.3f}')\n",
        "    return acc,f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHAVd9F09fBN"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCiOm_Iy9gnY"
      },
      "source": [
        "### ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbOYAuc2lFw5"
      },
      "source": [
        "- **Архитектура**: классическая CNN-модель ResNet-18, предобученная на ImageNet, с заменённым линейным слоем на число классов задачи.  \n",
        "- **Тренинг**: 4 эпохи, lr=1 e-4, AdamW + CosineAnnealingLR, label smoothing=0.1, накопление градиентов по батчу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyK4ndhfsGo-",
        "outputId": "e27a9f07-e6dd-4223-932e-c7c2d7331629",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01/4  train_acc 0.503  val_acc 0.630  val_F1 0.628\n",
            "E02/4  train_acc 0.738  val_acc 0.682  val_F1 0.683\n",
            "E03/4  train_acc 0.861  val_acc 0.709  val_F1 0.710\n",
            "E04/4  train_acc 0.931  val_acc 0.716  val_F1 0.717\n",
            "ResNet-18: acc 0.719  F1 0.719\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.7194719471947195, 0.7189772102520771)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "r18.fc = nn.Linear(r18.fc.in_features, NUM_CLASSES)\n",
        "r18,_ = fit(r18, tr_dl_cnn, epochs=4, lr=1e-4)\n",
        "evaluate(r18,'ResNet-18')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGfYjpwMlFw6"
      },
      "source": [
        "| Метрика      | Значение |\n",
        "|--------------|----------|\n",
        "| Accuracy     | 0.719    |\n",
        "| Macro F1     | 0.719    |\n",
        "| Best val_acc | 0.716 (эпоха 4) |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- Валид. точность выросла с 0.63 до 0.72 за 4 эпохи, затем стабилизировалась.  \n",
        "- Небольшой разрыв между train_acc (0.93) и val_acc (0.72) указывает на умеренную переобучаемость.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XiliccT9_0I"
      },
      "source": [
        "### Vit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i27JZ9bilFw6"
      },
      "source": [
        "- **Архитектура**: Vision Transformer (B/16), предобученный на ImageNet, с заменённым классифицирующим слоем под нужное число классов.  \n",
        "- **Тренинг**: 4 эпохи, lr = 5 × 10⁻⁵, градиентная аккумуляция (ACC_STEPS), AdamW + CosineAnnealingLR, label smoothing=0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q4lNlYksIX0",
        "outputId": "be58deca-fab8-4281-b024-5f19a8867fa3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:02<00:00, 150MB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01/4  train_acc 0.631  val_acc 0.746  val_F1 0.748\n",
            "E02/4  train_acc 0.839  val_acc 0.783  val_F1 0.785\n",
            "E03/4  train_acc 0.936  val_acc 0.796  val_F1 0.798\n",
            "E04/4  train_acc 0.979  val_acc 0.799  val_F1 0.801\n",
            "ViT-B/16: acc 0.797  F1 0.796\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.7969636963696369, 0.7963127553830418)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vit = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
        "vit.heads.head = nn.Linear(vit.heads.head.in_features, NUM_CLASSES)\n",
        "\n",
        "vit, _ = fit(vit, tr_dl_vit, epochs=4, lr=5e-5, accum=ACC_STEPS)\n",
        "evaluate(vit, 'ViT-B/16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDPaKcDjlFw6"
      },
      "source": [
        "| Метрика      | Значение                |\n",
        "|--------------|-------------------------|\n",
        "| Accuracy     | 0.797                   |\n",
        "| Macro F1     | 0.796                   |\n",
        "| Best val_acc | 0.799 (эпоха 4)         |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- ViT-База медленнее обучается на первых эпохах по сравнению с ResNet-18, но в итоге даёт заметно более высокую точность и F1.  \n",
        "- Рост train_acc от 0.63 до 0.98 при val_acc от 0.75 до 0.80 говорит о хорошей способности к обобщению.  \n",
        "- Transformer-архитектура показывает более устойчивую динамику и сильнее подходит для задачи классификации пищи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JMLPyDP9ygk"
      },
      "source": [
        "## Улучшенный baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9j-Zp88-QeE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_ds.dataset.transform = tf_strong\n",
        "\n",
        "tr_dl_strong_cnn = DataLoader(train_ds, BATCH_CNN, shuffle=True,\n",
        "                              generator=gen,\n",
        "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "tr_dl_strong_vit = DataLoader(train_ds, BATCH_VIT, shuffle=True,\n",
        "                              generator=gen,\n",
        "                              num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiS9RKpd-Ksi"
      },
      "source": [
        "### ResNet, но круче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y81NYdTllFw6"
      },
      "source": [
        "- **Архитектура**: ResNet-50, предобученный на ImageNet, с применением mixup (α=0.2) и сильных аугментаций (ColorJitter, RandomErasing) в тренировочном цикле.  \n",
        "- **Тренинг**: 5 эпох, lr = 1 × 10⁻⁴, gradient accumulation = ACC_STEPS, AdamW + CosineAnnealingLR, label smoothing=0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "2f50fc630ea64b36bfa88ac86fb80116",
            "49515674d2cf487083bf1589803abc41",
            "5511e12d3f2a41f2b5896bc898235b71",
            "f3ecb31eae8e4839b66543b0b7f5945c",
            "11476b6100a94fa281609bcfea755b7f",
            "1bfc1b77282e4cc9b0b41a8eaf2a235d",
            "8eea4306b9c9474ab18b848bdf4e6d30",
            "b92c7a53056d470ba4703cfd7aa4e28e",
            "f1319ec5406d407b9375c99da7832040",
            "27d85cfc1a584f39ae23a1fd9eb76c9d",
            "cae41bde9f5e48bcb091d8f50f7797c5",
            "c174291f5127443d94110fc4dc50f9c8"
          ]
        },
        "id": "Xca6RVqNsKJw",
        "outputId": "a1e8eaf0-5e85-4071-cccf-07c6d7e2ad84",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s] \n",
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E1/5  val_acc 0.574  val_F1 0.567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E2/5  val_acc 0.658  val_F1 0.654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E3/5  val_acc 0.702  val_F1 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E4/5  val_acc 0.724  val_F1 0.724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E5/5  val_acc 0.732  val_F1 0.729\n",
            "ResNet-50+Mix: acc 0.736  F1 0.733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.7361056105610561, 0.7330629654119782)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def mixup(x, y, alpha=0.2):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0))\n",
        "    return lam * x + (1 - lam) * x[idx], (y, y[idx], lam)\n",
        "\n",
        "def mix_loss(pred, tgt):\n",
        "    y1, y2, lam = tgt\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    return lam * criterion(pred, y1) + (1 - lam) * criterion(pred, y2)\n",
        "\n",
        "def train_r50_mix(epochs=5, lr=1e-4):\n",
        "    net = models.resnet50(\n",
        "        weights=models.ResNet50_Weights.IMAGENET1K_V2,\n",
        "    )\n",
        "    net.fc = nn.Linear(net.fc.in_features, NUM_CLASSES)\n",
        "    net.to(DEVICE)\n",
        "    opt = torch.optim.AdamW(\n",
        "        net.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=1e-4,\n",
        "    )\n",
        "    scaler = GradScaler()\n",
        "    best = {\"acc\": 0.0}\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        net.train()\n",
        "        opt.zero_grad()\n",
        "        for step, (x, y) in enumerate(\n",
        "            tqdm(tr_dl_strong_cnn, leave=False),\n",
        "            1,\n",
        "        ):\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "\n",
        "            xm, ym = mixup(x, y)\n",
        "            with autocast(device_type='cuda'):\n",
        "                out = net(xm)\n",
        "                loss = mix_loss(out, ym) / ACC_STEPS\n",
        "            scaler.scale(loss).backward()\n",
        "            if step % ACC_STEPS == 0 or step == len(tr_dl_strong_cnn):\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad()\n",
        "        _, val_acc, val_f1 = epoch_step(\n",
        "            net,\n",
        "            val_dl,\n",
        "            nn.CrossEntropyLoss(label_smoothing=0.1),\n",
        "        )\n",
        "        if val_acc > best[\"acc\"]:\n",
        "            best = {\n",
        "                \"acc\": val_acc,\n",
        "                \"f1\": val_f1,\n",
        "                \"state\": net.state_dict(),\n",
        "            }\n",
        "        print(\n",
        "            f\"E{epoch}/{epochs}  \"\n",
        "            f\"val_acc {val_acc:.3f}  \"\n",
        "            f\"val_F1 {val_f1:.3f}\",\n",
        "        )\n",
        "    net.load_state_dict(best[\"state\"])\n",
        "    return net, best\n",
        "\n",
        "r50, _ = train_r50_mix()\n",
        "evaluate(r50, \"ResNet-50+Mix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLHI-FymlFw6"
      },
      "source": [
        "| Метрика         | Значение            |\n",
        "|-----------------|---------------------|\n",
        "| Accuracy (test) | 0.736               |\n",
        "| Macro F1 (test) | 0.733               |\n",
        "| Best val_acc    | 0.732 (эпоха 5)     |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- Сильные аугментации + mixup дали заметный прирост по сравнению с ResNet-18 (+~0.02 acc).  \n",
        "- Быстрый рост val_acc до 0.73 за 5 эпох говорит об эффективном использовании регуляризации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjoEKbis-VD2"
      },
      "source": [
        "### Vit, но тоже круче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfZHH00AlFw6"
      },
      "source": [
        "- **Архитектура**: оконная Transformer-модель Swin-Tiny (~28 M параметров), head заменён на линейный слой под NUM_CLASSES.  \n",
        "- **Данные и аугментации**: Food101 с сильными аугментациями (ColorJitter, RandomErasing) + mixup.  \n",
        "- **Тренинг**: 4 эпохи, lr = 5 × 10⁻⁵, gradient accumulation, AdamW + CosineAnnealingLR, label smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTFNNHB--XZQ",
        "tags": [],
        "outputId": "c58c88c3-0f24-4a25-c141-79ef6be99b6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n",
            "100%|██████████| 108M/108M [00:01<00:00, 104MB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01/4  train_acc 0.421  val_acc 0.648  val_F1 0.643\n",
            "E02/4  train_acc 0.648  val_acc 0.706  val_F1 0.704\n",
            "E03/4  train_acc 0.705  val_acc 0.729  val_F1 0.729\n",
            "E04/4  train_acc 0.732  val_acc 0.744  val_F1 0.743\n",
            "Swin-T: acc 0.754  F1 0.751\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.7537953795379538, 0.7511911494530815)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "swin = models.swin_t(weights=models.Swin_T_Weights.IMAGENET1K_V1)\n",
        "swin.head = nn.Linear(swin.head.in_features, NUM_CLASSES)\n",
        "swin,_ = fit(swin, tr_dl_strong_vit, epochs=4, lr=5e-5, accum=ACC_STEPS)\n",
        "evaluate(swin,'Swin-T')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUSzX0bglFw7"
      },
      "source": [
        "| Метрика         | Значение                 |\n",
        "|-----------------|--------------------------|\n",
        "| Accuracy (test) | 0.754                    |\n",
        "| Macro F1 (test) | 0.751                    |\n",
        "| Best val_acc    | 0.744 (эпоха 4)          |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- Swin-T показывает лучший результат среди всех моделей: +0.017 acc по сравнению с ViT-B/16.  \n",
        "- Быстрый рост val_acc от 0.648 до 0.744 за всего 4 эпохи свидетельствует о хорошей обобщающей способности оконного внимания.  \n",
        "- Mixup и сильные аугментации эффективно regularize, но наиболее значимый прирост даёт сама архитектура Swin.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIWY7Klb-dru",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_ds.dataset.transform = tf_basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxO9Smjc-eU4"
      },
      "source": [
        "## Свои модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "algDIcK9-hUt"
      },
      "source": [
        "### Обычная"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8VNGeK_lFw7"
      },
      "source": [
        "- **Архитектура**:  \n",
        "  Три свёрточных блока (Conv–BN–ReLU) с MaxPool, затем AdaptiveAvgPool и два FC-слоя (256→256→n_cls) с Dropout.\n",
        "\n",
        "- **Тренинг**:  \n",
        "  12 эпох, lr=3×10⁻⁴, AdamW + CosineAnnealingLR, CrossEntropyLoss с label smoothing=0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wImJFqssL6R",
        "tags": [],
        "outputId": "6d8a9876-4ea8-4270-8f5f-5132d4a92c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01/12  train_acc 0.054  val_acc 0.070  val_F1 0.040\n",
            "E02/12  train_acc 0.085  val_acc 0.095  val_F1 0.065\n",
            "E03/12  train_acc 0.103  val_acc 0.106  val_F1 0.075\n",
            "E04/12  train_acc 0.117  val_acc 0.116  val_F1 0.088\n",
            "E05/12  train_acc 0.129  val_acc 0.133  val_F1 0.104\n",
            "E06/12  train_acc 0.141  val_acc 0.137  val_F1 0.117\n",
            "E07/12  train_acc 0.151  val_acc 0.147  val_F1 0.120\n",
            "E08/12  train_acc 0.158  val_acc 0.162  val_F1 0.138\n",
            "E09/12  train_acc 0.164  val_acc 0.155  val_F1 0.130\n",
            "E10/12  train_acc 0.169  val_acc 0.177  val_F1 0.151\n",
            "E11/12  train_acc 0.173  val_acc 0.180  val_F1 0.153\n",
            "E12/12  train_acc 0.174  val_acc 0.177  val_F1 0.150\n",
            "SimpleCNN: acc 0.188  F1 0.155\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.18785478547854786, 0.15547873104068644)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_cls):\n",
        "        super().__init__()\n",
        "        self.feat = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, n_cls),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.cls(self.feat(x))\n",
        "\n",
        "simp, _ = fit(\n",
        "    SimpleCNN(NUM_CLASSES),\n",
        "    tr_dl_cnn,\n",
        "    epochs=12,\n",
        "    lr=3e-4,\n",
        ")\n",
        "evaluate(simp, \"SimpleCNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4tcsJRklFw7"
      },
      "source": [
        "| Метрика       | Значение               |\n",
        "|---------------|------------------------|\n",
        "| Accuracy (test)   | 0.188                  |\n",
        "| Macro F1 (test)   | 0.155                  |\n",
        "| Best val_acc      | 0.180 (эпоха 11)       |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- Очень невысокие метрики говорят о том, что простая архитектура без мощных предобученных бэконов с трудом справляется с разнообразием классов Food101.  \n",
        "- Рост val_acc до 0.18 к 11-й эпохе, затем плато → модель быстро выходит на своё “предел” выразительности.  \n",
        "- Для серьёзных задач классификации нужны глубже сети или трансформеры с предобучением.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ_-SvUs-nDs"
      },
      "source": [
        "### Необычная"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R9Pk421lFw7"
      },
      "source": [
        "- **Архитектура**:  \n",
        "  Лёгкий ViT-подобный бинуарный блок:  \n",
        "  – Patch-эмбеддинг: Conv2d(kernel=16, stride=16) → 256-мерные токены.  \n",
        "  – Добавлен CLS-токен + позиционные эмбеддинги.  \n",
        "  – 4 Transformer-блока (MultiHeadAttention heads=4 + MLP(×4) + LayerNorm + residual).  \n",
        "  – Выход через LN и линейный классификатор.\n",
        "\n",
        "- **Тренинг**:  \n",
        "  12 эпох, lr=3×10⁻⁴, AdamW + CosineAnnealingLR, CrossEntropyLoss(label_smoothing=0.1), градиентный накопитель ACC_STEPS на ViT-даталоадер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHSnODGwsNZm",
        "tags": [],
        "outputId": "c339313c-bdec-4055-a2b9-04b403b14e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01/12  train_acc 0.063  val_acc 0.082  val_F1 0.057\n",
            "E02/12  train_acc 0.115  val_acc 0.127  val_F1 0.104\n",
            "E03/12  train_acc 0.150  val_acc 0.156  val_F1 0.127\n",
            "E04/12  train_acc 0.175  val_acc 0.180  val_F1 0.156\n",
            "E05/12  train_acc 0.200  val_acc 0.201  val_F1 0.182\n",
            "E06/12  train_acc 0.222  val_acc 0.219  val_F1 0.201\n",
            "E07/12  train_acc 0.247  val_acc 0.243  val_F1 0.231\n",
            "E08/12  train_acc 0.263  val_acc 0.254  val_F1 0.238\n",
            "E09/12  train_acc 0.284  val_acc 0.260  val_F1 0.245\n",
            "E10/12  train_acc 0.299  val_acc 0.272  val_F1 0.258\n",
            "E11/12  train_acc 0.309  val_acc 0.283  val_F1 0.271\n",
            "E12/12  train_acc 0.317  val_acc 0.284  val_F1 0.271\n",
            "TinyViT: acc 0.300  F1 0.281\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.29953795379537956, 0.2811939835013023)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Patch(nn.Module):\n",
        "    def __init__(self, img=224, ps=16, inp=3, dim=256):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(inp, dim, ps, ps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x).flatten(2).transpose(1, 2)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim=256, h=4, mlp=4, p=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n1 = nn.LayerNorm(dim)\n",
        "        self.att = nn.MultiheadAttention(\n",
        "            dim,\n",
        "            h,\n",
        "            dropout=p,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.n2 = nn.LayerNorm(dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mlp),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(dim * mlp, dim),\n",
        "            nn.Dropout(p),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        x = self.n1(x)\n",
        "        x, _ = self.att(x, x, x, need_weights=False)\n",
        "        x = x + y\n",
        "\n",
        "        y = x\n",
        "        x = self.n2(x)\n",
        "        x = self.ff(x) + y\n",
        "        return x\n",
        "\n",
        "class TinyViT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img=224,\n",
        "        ps=16,\n",
        "        cls=NUM_CLASSES,\n",
        "        dim=256,\n",
        "        d=4,\n",
        "        h=4,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = Patch(img, ps, 3, dim)\n",
        "        self.cls = nn.Parameter(torch.zeros(1, 1, dim))\n",
        "        self.pos = nn.Parameter(\n",
        "            torch.randn(1, (img // ps) ** 2 + 1, dim),\n",
        "        )\n",
        "\n",
        "        self.blks = nn.ModuleList([Block(dim, h) for _ in range(d)])\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, cls)\n",
        "\n",
        "        nn.init.trunc_normal_(self.pos, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        x = self.embed(x)\n",
        "        cls_tok = self.cls.expand(batch_size, -1, -1)\n",
        "        x = torch.cat((cls_tok, x), 1) + self.pos\n",
        "\n",
        "        for blk in self.blks:\n",
        "            x = blk(x)\n",
        "\n",
        "        x = self.norm(x)[:, 0]\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "tiny, _ = fit(\n",
        "    TinyViT(),\n",
        "    tr_dl_vit,\n",
        "    epochs=12,\n",
        "    lr=3e-4,\n",
        "    accum=ACC_STEPS,\n",
        ")\n",
        "evaluate(tiny, \"TinyViT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oNLbm1ElFxA"
      },
      "source": [
        "| Метрика       | Значение               |\n",
        "|---------------|------------------------|\n",
        "| Accuracy (test)   | 0.300                  |\n",
        "| Macro F1 (test)   | 0.281                  |\n",
        "| Best val_acc      | 0.284 (эпоха 12)       |\n",
        "\n",
        "### Краткие выводы\n",
        "\n",
        "- TinyViT показывает приемлемый прогресс (val_acc ≈ 0.28), но остаётся далеко позади крупных предобученных трансформеров.  \n",
        "- Литые размеры (256-мерный токен, 4 блока) ограничивают вместимость модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHVnkiht-qoV"
      },
      "source": [
        "## Результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnoJMVIavFAd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "metrics_cache = {}\n",
        "for name, model in [\n",
        "    ('ResNet-18',      r18),\n",
        "    ('ViT-B/16',       vit),\n",
        "    ('ResNet-50+Mix',  r50),\n",
        "    ('Swin-T',         swin),\n",
        "    ('SimpleCNN',      simp),\n",
        "    ('TinyViT',        tiny),\n",
        "]:\n",
        "    metrics_cache[name] = evaluate(model, name)\n",
        "\n",
        "print('\\n=== Итоговые accuracy ===')\n",
        "for k, (acc, _) in metrics_cache.items():\n",
        "    print(f'{k:13s}: {acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRl0vAjOlFxA"
      },
      "source": [
        "- **ResNet-18** (acc 0.719 / F1 0.719)  \n",
        "  Надёжный CNN-бейзлайн, быстро сходится и показывает сбалансированную точность на всех классах.\n",
        "\n",
        "- **ViT-B/16** (acc 0.797 / F1 0.796)  \n",
        "  Лучший результат благодаря мощному глобальному вниманию — трансформер отлично выучил особенности каждого класса.\n",
        "\n",
        "- **ResNet-50 + MixUp** (acc 0.736 / F1 0.733)  \n",
        "  Более глубокая CNN с миксап-аугментацией обходит ResNet-18, но до трансформеров немного не дотягивает.\n",
        "\n",
        "- **Swin-T** (acc 0.754 / F1 0.751)  \n",
        "  Локально-глобальный подход через «окна» даёт преимущество перед ResNet-18, уступая только ViT.\n",
        "\n",
        "- **SimpleCNN** (acc 0.188 / F1 0.155)  \n",
        "  Модель слишком малой глубины и без предварительной инициализации — не справляется с разнообразием классов.\n",
        "\n",
        "- **TinyViT** (acc 0.300 / F1 0.281)  \n",
        "  Лёгкий трансформер показывает ограниченные возможности при малом объёме данных и небольшой архитектуре."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}